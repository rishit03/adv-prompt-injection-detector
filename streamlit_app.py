# streamlit_app.py
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), "src"))  # ğŸ‘ˆ Add this!
import streamlit as st
import joblib
import streamlit as st
import joblib
from bert_features import encode_prompts  # Import your BERT encoder

# Set Streamlit page config
st.set_page_config(page_title="PromptShield AI 2.0", page_icon="ğŸ›¡ï¸", layout="centered")

# Title and description
st.title("ğŸ›¡ï¸ PromptShield AI 2.0 â€” Adversarial Prompt Injection Detection System")
st.markdown("Detect whether a user prompt is **Safe âœ…**, **Medium Risk âš ï¸**, or **High Risk ğŸš¨** using a BERT-powered machine learning model.")

# Paths
MODEL_PATH = "models/model.pkl"

# Load trained model
model = joblib.load(MODEL_PATH)

# Prediction function
# Prediction function with thresholding
def predict_prompt(prompt: str) -> str:
    embedding = encode_prompts([prompt])  # Encode single prompt
    proba = model.predict_proba(embedding)[0]  # Get class probabilities
    
    # Get safe class index
    safe_index = model.classes_.tolist().index('safe')
    safe_score = proba[safe_index]

    # Apply threshold (80% confidence to call it Safe)
    if safe_score >= 0.8:
        return "safe"
    else:
        return "injected"


# Streamlit UI
st.header("ğŸ” Analyze a Prompt")
prompt = st.text_area("âœï¸ Enter a prompt to analyze:", height=150)

# Session state to keep prompt history
if 'history' not in st.session_state:
    st.session_state.history = []

if st.button("ğŸ” Analyze Prompt"):
    if prompt.strip() == "":
        st.warning("âš ï¸ Please enter a prompt first!")
    else:
        with st.spinner('Analyzing...'):
            result = predict_prompt(prompt)
        
        # Record the result
        st.session_state.history.append((prompt, result))
        
        # Show result
        if result == "safe":
            st.success("âœ… Risk Level: LOW\n\nThis prompt is safe.")
        elif result == "injected":
            st.error("ğŸš¨ Risk Level: HIGH\n\nPrompt injection attempt detected!")
        else:
            st.info("âš ï¸ Risk Level: MEDIUM\n\nUnable to determine with high confidence.")

# Divider
st.divider()

# Prompt History Section
st.header("ğŸ•˜ Prompt Analysis History")
if st.session_state.history:
    for past_prompt, past_result in reversed(st.session_state.history[-5:]):  # Show last 5 only
        if past_result == "safe":
            st.success(f"âœ… {past_prompt}")
        elif past_result == "injected":
            st.error(f"ğŸš¨ {past_prompt}")
        else:
            st.info(f"âš ï¸ {past_prompt}")
else:
    st.write("No prompts analyzed yet!")
